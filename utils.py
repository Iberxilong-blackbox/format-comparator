def contains_cjk_characters(text: str) -> bool:
    """
    æ£€æŸ¥æ–‡æœ¬æ˜¯å¦åŒ…å«ä¸­æ—¥éŸ©(CJK)å­—ç¬¦
    
    ä»¥ä¸‹UnicodeèŒƒå›´åŒ…æ‹¬ï¼š
    - CJKç»Ÿä¸€æ±‰å­— (U+4E00-U+9FFF)
    - CJKæ‰©å±•A (U+3400-U+4DBF)
    - CJKæ‰©å±•B (U+20000-U+2A6DF)
    - CJKå…¼å®¹æ±‰å­— (U+F900-U+FAFF)
    - CJKéƒ¨é¦–æ‰©å±• (U+2E80-U+2EFF)
    - CJKç¬”ç”» (U+31C0-U+31EF)
    - ä¸­æ—¥éŸ©ç¬¦å·å’Œæ ‡ç‚¹ (U+3000-U+303F)
    - ä¸­æ–‡æ ‡ç‚¹ (U+FF00-U+FFEFéƒ¨åˆ†)
    
    Args:
        text: è¦æ£€æŸ¥çš„æ–‡æœ¬
        
    Returns:
        æ˜¯å¦åŒ…å«CJKå­—ç¬¦
    """
    # åŸºæœ¬æ±‰å­—å’Œå¸¸ç”¨æ‰©å±•
    if any('\u4e00' <= char <= '\u9fff' for char in text):
        return True
    
    # CJKæ‰©å±•A
    if any('\u3400' <= char <= '\u4dbf' for char in text):
        return True
    
    # CJKå…¼å®¹æ±‰å­—
    if any('\uf900' <= char <= '\ufaff' for char in text):
        return True
        
    # CJKéƒ¨é¦–æ‰©å±•
    if any('\u2e80' <= char <= '\u2eff' for char in text):
        return True
        
    # CJKç¬”ç”»
    if any('\u31c0' <= char <= '\u31ef' for char in text):
        return True
        
    # ä¸­æ—¥éŸ©ç¬¦å·å’Œæ ‡ç‚¹
    if any('\u3000' <= char <= '\u303f' for char in text):
        return True
        
    # å…¨è§’ASCIIã€æ‹‰ä¸æ–‡å­—æ¯å’Œä¸­æ–‡æ ‡ç‚¹ï¼ˆFF00-FFEFï¼‰ä¸­çš„ä¸­æ–‡æ ‡ç‚¹éƒ¨åˆ†
    if any(('\uff01' <= char <= '\uff0f') or ('\uff1a' <= char <= '\uff20') or 
           ('\uff3b' <= char <= '\uff40') or ('\uff5b' <= char <= '\uff65') for char in text):
        return True
        
    # å…¶ä»–å¸¸è§ä¸­æ–‡æ ‡ç‚¹
    chinese_puncts = 'ã€‚ï¼Œã€ï¼›ï¼šï¼Ÿï¼""''ï¼ˆï¼‰ã€ã€‘ã€Šã€‹ã€ˆã€‰ã€ã€ã€Œã€ï¹ƒï¹„ã€”ã€•â€¦â€”ï½ï¹ï¿¥'
    if any(char in chinese_puncts for char in text):
        return True
        
    return False

import json
import os
import re #ç¡®ä¿ re å·²å¯¼å…¥
import unicodedata # ç¡®ä¿å¯¼å…¥ unicodedata
from typing import List

# æ•°å­¦å­—ç¬¦è§„èŒƒåŒ–æ˜ å°„è¡¨
MATH_CHAR_NORM_MAP = {
    # Latin Mathematical Alphanumeric Symbols (subset from DocxProcessor)
    'ğœƒ': 'Î¸', 'ğ›¿': 'Î´', # 'ğ‘': 'a', 'ğ‘¥': 'x', # 'a' and 'x' might be too common, handle carefully or rely on NFKD
    # Italic (Lowercase)
    'ğ‘': 'a', 'ğ‘': 'b', 'ğ‘': 'c', 'ğ‘‘': 'd', 'ğ‘’': 'e', 'ğ‘“': 'f', 'ğ‘”': 'g', 'â„': 'h', 'ğ‘–': 'i', 'ğ‘—': 'j',
    'ğ‘˜': 'k', 'ğ‘™': 'l', 'ğ‘š': 'm', 'ğ‘›': 'n', 'ğ‘œ': 'o', 'ğ‘': 'p', 'ğ‘': 'q', 'ğ‘Ÿ': 'r', 'ğ‘ ': 's', 'ğ‘¡': 't',
    'ğ‘¢': 'u', 'ğ‘£': 'v', 'ğ‘¤': 'w', 'ğ‘¥': 'x', 'ğ‘¦': 'y', 'ğ‘§': 'z',
    # Italic (Uppercase)
    'ğ´': 'A', 'ğµ': 'B', 'ğ¶': 'C', 'ğ·': 'D', 'ğ¸': 'E', 'ğ¹': 'F', 'ğº': 'G', 'ğ»': 'H', 'ğ¼': 'I', 'ğ½': 'J',
    'ğ¾': 'K', 'ğ¿': 'L', 'ğ‘€': 'M', 'ğ‘': 'N', 'ğ‘‚': 'O', 'ğ‘ƒ': 'P', 'ğ‘„': 'Q', 'ğ‘…': 'R', 'ğ‘†': 'S', 'ğ‘‡': 'T',
    'ğ‘ˆ': 'U', 'ğ‘‰': 'V', 'ğ‘Š': 'W', 'ğ‘‹': 'X', 'ğ‘Œ': 'Y', 'ğ‘': 'Z',
    # Bold (Lowercase)
    'ğš': 'a', 'ğ›': 'b', 'ğœ': 'c', 'ğ': 'd', 'ğ': 'e', 'ğŸ': 'f', 'ğ ': 'g', 'ğ¡': 'h', 'ğ¢': 'i', 'ğ£': 'j',
    'ğ¤': 'k', 'ğ¥': 'l', 'ğ¦': 'm', 'ğ§': 'n', 'ğ¨': 'o', 'ğ©': 'p', 'ğª': 'q', 'ğ«': 'r', 'ğ¬': 's', 'ğ­': 't',
    'ğ®': 'u', 'ğ¯': 'v', 'ğ°': 'w', 'ğ±': 'x', 'ğ²': 'y', 'ğ³': 'z',
    # Bold (Uppercase)
    'ğ€': 'A', 'ğ': 'B', 'ğ‚': 'C', 'ğƒ': 'D', 'ğ„': 'E', 'ğ…': 'F', 'ğ†': 'G', 'ğ‡': 'H', 'ğˆ': 'I', 'ğ‰': 'J',
    'ğŠ': 'K', 'ğ‹': 'L', 'ğŒ': 'M', 'ğ': 'N', 'ğ': 'O', 'ğ': 'P', 'ğ': 'Q', 'ğ‘': 'R', 'ğ’': 'S', 'ğ“': 'T',
    'ğ”': 'U', 'ğ•': 'V', 'ğ–': 'W', 'ğ—': 'X', 'ğ˜': 'Y', 'ğ™': 'Z',
    # Greek Mathematical Alphanumeric Symbols (subset from DocxProcessor)
    # Italic (Lowercase)
    'ğ›¼': 'Î±', 'ğ›½': 'Î²', 'ğ›¾': 'Î³', # 'ğ›¿': 'Î´', (already above)
    'ğœ€': 'Îµ', 'ğœ': 'Î¶', 'ğœ‚': 'Î·', # 'ğœƒ': 'Î¸', (already above)
    'ğœ„': 'Î¹', 'ğœ…': 'Îº', 'ğœ†': 'Î»', 'ğœ‡': 'Î¼', 'ğœˆ': 'Î½', 'ğœ‰': 'Î¾', 'ğœŠ': 'Î¿', 'ğœ‹': 'Ï€', 'ğœŒ': 'Ï',
    'ğœ': 'Ïƒ', 'ğœ': 'Ï„', 'ğœ': 'Ï…', 'ğœ‘': 'Ï†', 'ğœ’': 'Ï‡', 'ğœ“': 'Ïˆ', 'ğœ”': 'Ï‰',
    # Italic (Uppercase)
    'ğš¨': 'Î‘', 'ğš©': 'Î’', 'ğšª': 'Î“', 'ğš«': 'Î”', 'ğš¬': 'Î•', 'ğš­': 'Î–', 'ğš®': 'Î—', 'ğš¯': 'Î˜', 'ğš°': 'Î™', 'ğš±': 'Îš',
    'ğš²': 'Î›', 'ğš³': 'Îœ', 'ğš´': 'Î', 'ğšµ': 'Î', 'ğš¶': 'ÎŸ', 'ğš·': 'Î ', 'ğš¸': 'Î¡', 'ğšº': 'Î£', 'ğš»': 'Î¤',
    'ğš¼': 'Î¥', 'ğš½': 'Î¦', 'ğš¾': 'Î§', 'ğš¿': 'Î¨', 'ğ›€': 'Î©',
    # Add more mappings as needed, e.g., for bold Greek, script, fraktur, double-struck, etc.
    # Common symbols that might differ
    'â‰ ': '=', # Not equal to equal (for looser comparison if desired, or handle separately)
    '~': '~', # Tilde, often used in math, ensure it's consistent
    # Consider other symbols like plus, minus, dot, etc. if they have multiple Unicode representations
}


# é»˜è®¤çš„æ ‡é¢˜æ ·å¼åˆ—è¡¨ï¼Œä½œä¸ºå›é€€é€‰é¡¹
DEFAULT_HEADING_STYLES = ["æ ‡é¢˜ä¸€", "æ ‡é¢˜äºŒ", "æ ‡é¢˜ä¸‰", "æ ‡é¢˜å››"]

def extract_heading_styles_from_template(template_path: str = "templates/default.json") -> List[str]:
    """
    ä»æŒ‡å®šçš„æ¨¡æ¿JSONæ–‡ä»¶ä¸­æå–åŒ…å«â€œæ ‡é¢˜â€çš„æ ·å¼åç§°ï¼Œå¹¶æŒ‰çº§åˆ«æ’åºã€‚

    Args:
        template_path: æ¨¡æ¿JSONæ–‡ä»¶çš„è·¯å¾„ã€‚

    Returns:
        æ’åºåçš„æ ‡é¢˜æ ·å¼åç§°åˆ—è¡¨ã€‚å¦‚æœå‡ºé”™æˆ–æœªæ‰¾åˆ°ï¼Œåˆ™è¿”å›é»˜è®¤åˆ—è¡¨çš„å‰¯æœ¬ã€‚
    """
    heading_styles = []
    try:
        # æ£€æŸ¥æ¨¡æ¿æ–‡ä»¶æ˜¯å¦å­˜åœ¨
        if not os.path.exists(template_path):
            print(f"è­¦å‘Š: æ¨¡æ¿é…ç½®æ–‡ä»¶ {template_path} æœªæ‰¾åˆ°ã€‚å°†ä½¿ç”¨é»˜è®¤åˆ—è¡¨ã€‚")
            return DEFAULT_HEADING_STYLES[:] # è¿”å›å‰¯æœ¬

        with open(template_path, 'r', encoding='utf-8') as f:
            template_config = json.load(f)

            # æ£€æŸ¥ JSON ç»“æ„æ˜¯å¦ç¬¦åˆé¢„æœŸ
            if "æ ·å¼" not in template_config or not isinstance(template_config["æ ·å¼"], dict):
                print(f"è­¦å‘Š: åœ¨ {template_path} ä¸­æœªæ‰¾åˆ°æœ‰æ•ˆçš„ 'æ ·å¼' å­—å…¸ã€‚å°†ä½¿ç”¨é»˜è®¤åˆ—è¡¨ã€‚")
                return DEFAULT_HEADING_STYLES[:] # è¿”å›å‰¯æœ¬

            # æå–åŒ…å«â€œæ ‡é¢˜â€çš„æ ·å¼åç§°
            heading_styles = [
                style_name for style_name in template_config["æ ·å¼"]
                if isinstance(style_name, str) and "æ ‡é¢˜" in style_name
            ]

            # å¦‚æœæ²¡æœ‰æå–åˆ°ä»»ä½•æ ‡é¢˜æ ·å¼
            if not heading_styles:
                print(f"è­¦å‘Š: æœªèƒ½ä» {template_path} æå–åˆ°ä»»ä½•åŒ…å«'æ ‡é¢˜'çš„æ ·å¼ã€‚å°†ä½¿ç”¨é»˜è®¤åˆ—è¡¨ã€‚")
                return DEFAULT_HEADING_STYLES[:] # è¿”å›å‰¯æœ¬

            # å®šä¹‰æ’åºå‡½æ•°ï¼ŒæŒ‰æ ‡é¢˜çº§åˆ«æ’åº
            def get_heading_level(style_name):
                # å°è¯•åŒ¹é…ä¸­æ–‡æ•°å­— "æ ‡é¢˜ä¸€", "æ ‡é¢˜äºŒ", ...
                match_cn = re.search(r'æ ‡é¢˜([ä¸€äºŒä¸‰å››äº”å…­ä¸ƒå…«ä¹])', style_name)
                if match_cn:
                    num_map = {'ä¸€': 1, 'äºŒ': 2, 'ä¸‰': 3, 'å››': 4, 'äº”': 5, 'å…­': 6, 'ä¸ƒ': 7, 'å…«': 8, 'ä¹': 9}
                    return num_map.get(match_cn.group(1), 99) # é»˜è®¤å€¼è®¾ä¸ºè¾ƒå¤§æ•°

                # å°è¯•åŒ¹é…é˜¿æ‹‰ä¼¯æ•°å­— "æ ‡é¢˜1", "æ ‡é¢˜2", ...
                match_num = re.search(r'æ ‡é¢˜(\d+)', style_name)
                if match_num:
                    try:
                        return int(match_num.group(1))
                    except ValueError:
                        return 99 # å¦‚æœæ•°å­—è½¬æ¢å¤±è´¥

                # å¦‚æœä¸¤ç§æ¨¡å¼éƒ½åŒ¹é…ä¸ä¸Šï¼Œè¿”å›ä¸€ä¸ªè¾ƒå¤§çš„é»˜è®¤å€¼ï¼Œä½¿å…¶æ’åœ¨åé¢
                return 99

            # åº”ç”¨æ’åº
            heading_styles.sort(key=get_heading_level)

    except json.JSONDecodeError:
        print(f"è­¦å‘Š: æ¨¡æ¿é…ç½®æ–‡ä»¶ {template_path} æ ¼å¼é”™è¯¯ã€‚å°†ä½¿ç”¨é»˜è®¤åˆ—è¡¨ã€‚")
        return DEFAULT_HEADING_STYLES[:] # è¿”å›å‰¯æœ¬
    except Exception as e:
        # æ•è·å…¶ä»–å¯èƒ½çš„å¼‚å¸¸ï¼Œä¾‹å¦‚è¯»å–æ–‡ä»¶æ—¶çš„æƒé™é—®é¢˜ç­‰
        print(f"è­¦å‘Š: ä»æ¨¡æ¿æå–æ ‡é¢˜æ ·å¼æ—¶å‘ç”Ÿæ„å¤–é”™è¯¯: {e}ã€‚å°†ä½¿ç”¨é»˜è®¤åˆ—è¡¨ã€‚")
        return DEFAULT_HEADING_STYLES[:] # è¿”å›å‰¯æœ¬

    # æœ€ç»ˆè¿”å›æå–å¹¶æ’åºåçš„åˆ—è¡¨
    return heading_styles

# --- Functions moved from format_comparator.py ---

def _number_to_chinese(num: int) -> str:
    """å°†æ•°å­— 1-9 è½¬æ¢ä¸ºä¸­æ–‡æ•°å­—ã€‚"""
    chinese_map = {1: "ä¸€", 2: "äºŒ", 3: "ä¸‰", 4: "å››", 5: "äº”", 6: "å…­", 7: "ä¸ƒ", 8: "å…«", 9: "ä¹"}
    return chinese_map.get(num, str(num))


def _is_primarily_east_asian(text: str) -> bool:
    """Checks if the text contains a significant portion of East Asian characters."""
    if not text:
        return False
    east_asian_count = 0
    total_count = 0
    # Basic check for CJK Unified Ideographs, Hangul Syllables, Hiragana, Katakana
    # More comprehensive ranges can be added if needed.
    for char in text:
        total_count += 1
        # CJK Unified Ideographs U+4E00 to U+9FFF
        if '\u4e00' <= char <= '\u9fff':
            east_asian_count += 1
        # Hangul Syllables U+AC00 to U+D7AF
        elif '\uac00' <= char <= '\ud7af':
            east_asian_count += 1
        # Hiragana U+3040 to U+309F
        elif '\u3040' <= char <= '\u309f':
            east_asian_count += 1
        # Katakana U+30A0 to U+30FF
        elif '\u30a0' <= char <= '\u30ff':
            east_asian_count += 1

    # Heuristic: If more than 30% are East Asian characters, consider it primarily East Asian
    # This threshold might need adjustment based on typical content.
    return total_count > 0 and (east_asian_count / total_count) > 0.3


def normalize_text(text: str, NORM_FORM='NFKC') -> str: # Added NORM_FORM parameter
    """
    è§„èŒƒåŒ–æ–‡æœ¬ä»¥ä¾¿æ¯”è¾ƒï¼š
    1. ç¡®ä¿æ˜¯å­—ç¬¦ä¸²ã€‚
    2. (å¯é€‰) Unicode è§„èŒƒåŒ– (ä¾‹å¦‚ NFKC)ã€‚
    3. å¯¹æ•°å­¦å­—æ¯æ•°å­—ç¬¦å·ç­‰è¿›è¡Œè‡ªå®šä¹‰è§„èŒƒåŒ–ã€‚
    4. ç§»é™¤ç‰¹æ®Šçš„ "[FORMULA:]" æ ‡è®°åŠå…¶ä¸¤ä¾§å¯èƒ½çš„ç©ºæ ¼ã€‚
    5. å°†æ‰€æœ‰ç±»å‹çš„æ¢è¡Œç¬¦ç»Ÿä¸€ä¸º '\n'ã€‚
    6. å°†è¿ç»­çš„å†…éƒ¨ç©ºç™½å­—ç¬¦ï¼ˆåŒ…æ‹¬ç©ºæ ¼ã€åˆ¶è¡¨ç¬¦ã€æ¢è¡Œç¬¦ï¼‰æ›¿æ¢ä¸ºå•ä¸ªç©ºæ ¼ã€‚
    7. å»é™¤é¦–å°¾ç©ºç™½ã€‚
    """
    if not isinstance(text, str):
        text = str(text)

    # 1. (å¯é€‰) Unicode è§„èŒƒåŒ–
    if NORM_FORM:
        text = unicodedata.normalize(NORM_FORM, text)

    # 2. å­—ç¬¦è§„èŒƒåŒ– (è‡ªå®šä¹‰æ•°å­¦ç¬¦å·ç­‰)
    normalized_char_list = []
    for char_in_text in text:
        normalized_char_list.append(MATH_CHAR_NORM_MAP.get(char_in_text, char_in_text))
    text = "".join(normalized_char_list)

    # 3. ç§»é™¤ [FORMULA:] æ ‡è®°
    text = text.replace(" [FORMULA:] ", " ")
    text = text.replace("[FORMULA:] ", " ")
    text = text.replace(" [FORMULA:]", " ")
    text = text.replace("[FORMULA:]", "")

    # 4. ç»Ÿä¸€æ¢è¡Œç¬¦
    text = text.replace('\r\n', '\n').replace('\r', '\n')
    
    # 5. åˆå¹¶è¿ç»­ç©ºç™½ï¼ˆåŒ…æ‹¬å› ä¸Šè¿°æ›¿æ¢äº§ç”Ÿçš„å¤šä½™ç©ºæ ¼ï¼‰
    text = re.sub(r'\s+', ' ', text)
    
    # 6. æœ€åå»é™¤é¦–å°¾ç©ºç™½
    return text.strip()